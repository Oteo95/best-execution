{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "filled-clone",
   "metadata": {},
   "source": [
    "<center><h1>Hands-On Reinforcement Learning Applied to Trade Execution Algorithms</h1></center>\n",
    "<center>\n",
    "Autor: <cite><a href=\"https://www.linkedin.com/in/aoteog/\">Oteo García, Alberto</a></cite>\n",
    "</center>\n",
    "<center>\n",
    "Autor: <cite><a href=\"https://www.linkedin.com/in/jesus-sanz/\">Sanz del Real, Jesús</a></cite>\n",
    "</center>\n",
    "\n",
    "----------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import Any, List, Sequence, Tuple\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/orderbook.pkl\", \"rb\") as f:\n",
    "        dict_ = pickle.load(f)\n",
    "dict_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c3ed3f-7880-4a58-aea2-37f56dc8ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict_['train']\n",
    "look_back = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02be03fa-50db-4689-a8af-bc7bcbe1e27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Inicialización de la clase del entorno que simula\n",
    "el libro de ordenes.\n",
    "----------------------------------------------------\n",
    "Input:\n",
    "    - data: \n",
    "        Dataframe con los datos previamente\n",
    "        agrupados del libro de órdenes.\n",
    "\n",
    "    - look_back: \n",
    "        Ventana para la generación de features\n",
    "        roladas en el instante t=0 del episodio.\n",
    "        Esta ventana representa el rango máximo para\n",
    "        la construcción de features.\n",
    "----------------------------------------------------\n",
    "Variables Internas:\n",
    "    - episode_bins:\n",
    "        Número de bines (steps) del episodio.\n",
    "    - episode_full_len:\n",
    "        Es igual a look_back + episode_bins.\n",
    "    - vol_care:\n",
    "        Volumen total (en títulos) de la orden care.\n",
    "    - actions_fn:\n",
    "        Diccionario con las posibles acciones del agente.\n",
    "        Las claves acceden a la función que evalúa  la acción\n",
    "        tomada por el agente.\n",
    "    - n_actions:\n",
    "        Número de acciones posibles.\n",
    "    - n_features:\n",
    "        Número de características de los estados.\n",
    "    - episode:\n",
    "        Dataframe que contiene los steps y estados del episodio.\n",
    "    - episode_full:\n",
    "        Es el episode añadiendo el look_back antes del comienzo \n",
    "        del episodio.\n",
    "    - episode_vwap:\n",
    "        VWAP de mercado al final del episodio.\n",
    "    - market_ep_vol:\n",
    "        Volumen (títulos) ejecutado por el mercado en cada bin del episodio.\n",
    "    - state_pos:\n",
    "        Número de step en el que nos encontramos.\n",
    "    - exec_vol:\n",
    "        Acumulado de títulos ejecutados por el algoritmo.\n",
    "    - action_hist:\n",
    "        Lista de acciones tomadas por el algoritmo en cada step.\n",
    "    - market_vwap_hist:\n",
    "        Lista de VWAP de mercado en cada step.\n",
    "    - reward_hist:\n",
    "        Lista de rewards obtenidas en cada step.\n",
    "    - price_hist:\n",
    "        Lista de precios ejecutados en cada step.\n",
    "    - vol_hist:\n",
    "        Lista de títulos ejecutados en cada step.                \n",
    "\"\"\"\n",
    "\n",
    "# Fixed params\n",
    "data = data\n",
    "look_back = look_back\n",
    "episode_bins = None\n",
    "episode_full_len = None\n",
    "vol_care = None\n",
    "\n",
    "def _do_nothing():\n",
    "    return\n",
    "\n",
    "def _agg_action():\n",
    "    return\n",
    "\n",
    "actions_fn = {\n",
    "    0: _do_nothing,\n",
    "    1: _agg_action,\n",
    "}\n",
    "\n",
    "n_actions = len(actions_fn)\n",
    "\n",
    "def _detect_num_feat():\n",
    "    return\n",
    "\n",
    "n_features = _detect_num_feat()\n",
    "\n",
    "# Data variables\n",
    "episode = None\n",
    "episode_full = None\n",
    "\n",
    "# Env variables\n",
    "episode_vwap = None\n",
    "market_ep_vol = None\n",
    "state_pos = 0\n",
    "exec_vol = 0\n",
    "actions_hist = []\n",
    "algo_vwap_hist = []\n",
    "market_vwap_hist = []\n",
    "reward_hist = []\n",
    "price_hist = []\n",
    "vol_hist = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27ea932-f349-4b1f-9007-5fed3279d85e",
   "metadata": {},
   "source": [
    "### 1. _generate_episode_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ca6ca5-9a54-4e6e-98d8-25b8a83d73f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _generate_episode_params():\n",
    "\"\"\"Se determinan las características de la orden a ejecutar.\n",
    "La órden queda definida por: \n",
    " - episode_bins:\n",
    "     Obtención de un número entero aleatorio [400, 600] \n",
    "     con una distribución uniforme.\n",
    " - vol_care:\n",
    "     Obtención del porcentaje de steps en el que hay que \n",
    "     ejecutar una órden para cubrir la órden care. \n",
    "     vol_care responde a un valor uniforme [0.075, 0.125]\n",
    "     multiplicado por el número self.episode_bins. \n",
    "     Lo convertimos a entero.\n",
    "\"\"\"\n",
    "# TODO: Int aleatorio entre 400 y 600 como un objeto numpy\n",
    "episode_bins = np.random.randint(low=400, high=600)\n",
    "# TODO: Float aleatorio entre 0.075 y 0.125\n",
    "pct_bins = np.random.uniform(low=0.075, high=0.125)\n",
    "# TODO: Int multiplicacion pct_bins y episode_bins\n",
    "vol_care = int(pct_bins * episode_bins)\n",
    "\n",
    "episode_full_len = episode_bins + look_back\n",
    "\n",
    "assert episode_bins <= 600\n",
    "assert episode_bins >= 400\n",
    "assert vol_care <= int(episode_bins * 0.125)\n",
    "assert vol_care >= int(episode_bins * 0.075)\n",
    "assert isinstance(vol_care, int)\n",
    "\n",
    "def _generate_episode_params():\n",
    "    episode_bins = np.random.randint(low=400, high=600)\n",
    "    pct_bins = np.random.uniform(low=0.075, high=0.125)\n",
    "    vol_care = int(pct_bins * episode_bins)\n",
    "    episode_full_len = episode_bins + look_back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34365eb-6276-4378-8e1a-aa8e378d40cb",
   "metadata": {},
   "source": [
    "### 2. _generate_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e7ec35-85d3-446c-9868-bbbd15a4a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _generate_episode():\n",
    "\"\"\"Obtenemos el día y hora en el que comienza el episodio.\n",
    "\"\"\"\n",
    "lenght_episode = 0\n",
    "while lenght_episode != episode_full_len:\n",
    "    # TODO: Selección de un dia entre los posibles.\n",
    "    # Clue: Usa np.random.choice y los dias data.keys\n",
    "    selected_day = np.random.choice(\n",
    "            list(data.keys()\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # TODO: Extrae selected_day de data\n",
    "    data_day = data[selected_day]\n",
    "\n",
    "    # TODO: selecciona una hora de inicio aleatoria\n",
    "    init_time = np.random.choice(data_day.index)\n",
    "\n",
    "    hour_pos = data_day.index.get_loc(init_time)\n",
    "    initial_position = hour_pos - look_back\n",
    "    final_position = hour_pos + episode_bins\n",
    "\n",
    "    if initial_position < 0:\n",
    "        continue\n",
    "    else:\n",
    "        # TODO: Filtra data_day entre por initial_position y final_position\n",
    "        episode_full = data_day.iloc[initial_position:final_position, :]\n",
    "\n",
    "        # TODO: Filtra data_day entre por hour_pos y final_position\n",
    "        episode = data_day.iloc[hour_pos:final_position, :]\n",
    "\n",
    "        lenght_episode = episode_full.shape[0]\n",
    "\n",
    "def _generate_episode():\n",
    "    lenght_episode = 0\n",
    "    while lenght_episode != episode_full_len:\n",
    "        selected_day = np.random.choice(\n",
    "                list(data.keys()\n",
    "            )\n",
    "        )\n",
    "        data_day = data[selected_day]\n",
    "        init_time = np.random.choice(data_day.index)\n",
    "        hour_pos = data_day.index.get_loc(init_time)\n",
    "        initial_position = hour_pos - look_back\n",
    "        final_position = hour_pos + episode_bins\n",
    "        if initial_position < 0:\n",
    "            continue\n",
    "        else:\n",
    "            episode_full = data_day.iloc[initial_position:final_position, :]\n",
    "            episode = data_day.iloc[hour_pos:final_position, :]\n",
    "            lenght_episode = episode_full.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025ff33b-106b-4391-bbe3-66b3776df673",
   "metadata": {},
   "source": [
    "### 3. observation_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b833c0c1-2366-40f0-8960-fe1608154e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def observation_builder() -> np.array:\n",
    "\"\"\" Función para la construcción de las observaciones del estado.\n",
    "    ------------------------------------------------------------\n",
    "    Default:\n",
    "        - Primera característica es tiempo restante en porcentaje.\n",
    "        - Seguna característica es el volumen restante en porcentaje.\n",
    "\"\"\"\n",
    "# TODO: Construye el vector con las dos características de la descripción\n",
    "# Clue: Utiliza episode_bins, state_pos, exec_vol ,vol_care\n",
    "time_left = (episode_bins - state_pos) / episode_bins\n",
    "vol_left = 1 - (exec_vol / vol_care)\n",
    "obs  = np.array([time_left, vol_left])\n",
    "\n",
    "print(obs)\n",
    "\n",
    "def observation_builder() -> np.array:\n",
    "    time_left = (episode_bins - state_pos) / episode_bins\n",
    "    vol_left = 1 - (exec_vol / vol_care)\n",
    "    obs  = np.array([time_left, vol_left])\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8a8c19-c58e-4735-867f-6b741a20f0b2",
   "metadata": {},
   "source": [
    "### 4. _compute_episode_market_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6293419-14e7-465e-946a-d2df01186480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _compute_episode_market_feat() -> Tuple[float, float]:\n",
    "\"\"\"Cálculo de los valores VWAP y Market Vol del episodio.\n",
    "Como no tenemos las ejecuciones de mercado, asumimos que el \n",
    "precio es el mid price de cada step.\n",
    "\"\"\"\n",
    "# TODO: Calcula el mid price utilizando ask1 y bid1 de episode\n",
    "# Opcional: Utiliza un precio más realista para el mkt VWAP\n",
    "mid = (episode[\"ask1\"] + episode[\"bid1\"]) / 2\n",
    "# TODO: Calcula market_ep_vol\n",
    "market_ep_vol = episode.cumvol.diff()\n",
    "market_ep_vol[0] = 0\n",
    "# TODO: calcula el volumen acumulado del mercado en todo el episodio\n",
    "cum_vol = market_ep_vol.sum()\n",
    "# TODO: calcula el episode_vwap\n",
    "episode_vwap = (mid[:-1] * market_ep_vol[1:]).sum() / cum_vol\n",
    "\n",
    "print(episode_vwap)\n",
    "print(market_ep_vol)\n",
    "\n",
    "def _compute_episode_market_feat(self) -> Tuple[float, float]:\n",
    "    mid = (episode[\"ask1\"] + episode[\"bid1\"]) / 2\n",
    "    # TODO: Calcula market_ep_vol\n",
    "    market_ep_vol = episode.cumvol.diff()\n",
    "    market_ep_vol[0] = 0\n",
    "    # TODO: calcula el volumen acumulado del mercado en todo el episodio\n",
    "    cum_vol = market_ep_vol.sum()\n",
    "    # TODO: calcula el episode_vwap\n",
    "    episode_vwap = (mid[:-1] * market_ep_vol[1:]).sum() / cum_vol\n",
    "    return episode_vwap, market_ep_vol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6540a880-ea07-48c2-a9ce-88562d4b6e08",
   "metadata": {},
   "source": [
    "### 5. _compute_market_vwap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e4d8f-1676-494e-96a7-22046c5d242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _compute_market_vwap() -> float:\n",
    "\"\"\"Cálculo del VWAP del mercado hasta el step actual.\n",
    "\"\"\"\n",
    "# TODO: Establece un para el vol ejecutado por el mkt en cada step\n",
    "# Clue: puedes fijarte en _compute_episode_market_feat\n",
    "mid_p = (episode[\"ask1\"] + episode[\"bid1\"]) / 2\n",
    "mkt_p = (mid_p + mid_p.shift(-1).ffill()) / 2\n",
    "# Calcula todos los vwap del mkt hasta el step actual incluido\n",
    "v = episode[\"cumvol\"].diff().shift(-1)\n",
    "p_arr = mkt_p.values[:state_pos + 1]\n",
    "v_arr = v.values[:state_pos + 1]\n",
    "sum_vol = np.sum(v_arr)\n",
    "# Si el mkt vol hasta el step == 0, devuelve el último precio hasta el step\n",
    "if sum_vol == 0:\n",
    "    market_vwap = p_arr[-1]\n",
    "else:\n",
    "    # Calcula y devuelve el vwap acumulado hasta el step\n",
    "    market_vwap = np.sum(p_arr * v_arr) / sum_vol\n",
    "\n",
    "print(market_vwap)\n",
    "\n",
    "def _compute_market_vwap() -> float:\n",
    "    mid_p = (episode[\"ask1\"] + episode[\"bid1\"]) / 2\n",
    "    mkt_p = (mid_p + mid_p.shift(-1).ffill()) / 2\n",
    "    v = episode[\"cumvol\"].diff().shift(-1)\n",
    "    p_arr = mkt_p.values[:state_pos + 1]\n",
    "    v_arr = v.values[:state_pos + 1]\n",
    "    sum_vol = np.sum(v_arr)\n",
    "    if sum_vol == 0:\n",
    "        return p_arr[-1]\n",
    "    market_vwap = np.sum(p_arr * v_arr) / sum_vol\n",
    "    return market_vwap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b52217-6387-4073-a572-be6e48442c53",
   "metadata": {},
   "source": [
    "### 6. _compute_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d67bd2-1ce8-4fb8-991f-b4e99dfd6abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = 0\n",
    "vol = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e0f495-f109-42d0-8901-c582a2347d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _compute_reward(price: float, vol: float) -> float:\n",
    "\"\"\"Función de diseño de los rewards y penalizaciónes que \n",
    "recibe el algoritmo al tomar las acciones.\n",
    "--------------------------------------------------------\n",
    "Default:\n",
    "    - El reward es el ratio de la diferencia entre el episode_vwap y\n",
    "      el precio de la acción tomada, dividido entre episode_vwap.\n",
    "\"\"\"\n",
    "# TODO: Establece y devuelve un reward cuando vol == 0\n",
    "if vol == 0:\n",
    "    reward = 0\n",
    "    print(reward)\n",
    "# TODO: Calcula y devuelve el reward cuando vol > 0\n",
    "# Clue: Utiliza episode_vwap y price para la reward por defecto\n",
    "# Opcional: Utiliza el self y elimina los parámetros de la función\n",
    "reward = (episode_vwap - price) / episode_vwap\n",
    "print(reward)\n",
    "\n",
    "def _compute_reward(price: float, vol: float) -> float:\n",
    "    if vol == 0:\n",
    "        reward = 0\n",
    "        return reward\n",
    "    reward = (episode_vwap - price) / episode_vwap\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca87f5da-2bae-4fe2-a69a-cb72310ec537",
   "metadata": {},
   "source": [
    "### 7-8. _agg_action & _compute_algo_vwap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bf3ff3-d643-49e9-bb5e-d8f8091a9ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _compute_algo_vwap() -> float:\n",
    "\"\"\"Cálculo del VWAP del algoritmo hasta el step actual.\n",
    "\"\"\"\n",
    "# TODO: Calcula el algo_vwap\n",
    "# Clue: utiliza price_hist, vol_hist\n",
    "p_arr = np.array(price_hist)\n",
    "v_arr = np.array(vol_hist)\n",
    "algo_vwap = np.sum(p_arr * v_arr) / np.sum(v_arr)\n",
    "\n",
    "print(algo_vwap)\n",
    "\n",
    "def _compute_algo_vwap() -> float:\n",
    "    p_arr = np.array(price_hist)\n",
    "    v_arr = np.array(vol_hist)\n",
    "    algo_vwap = np.sum(p_arr * v_arr) / np.sum(v_arr)\n",
    "    return algo_vwap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606ad2aa-e0d4-49c5-afe4-dd9a3e4a572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _agg_action() -> float:\n",
    "\"\"\"Acción agresiva de compra de un título a precio de episode['ask1'].\n",
    "Devolvemos el reward asociado a esa acción.\n",
    "\"\"\"\n",
    "# TODO: obtén el precio de la accion agresiva (ask1) en el state_pos\n",
    "price = episode[\"ask1\"].values[state_pos]\n",
    "# TODO: guarda price en price_hist, añade 1 a exec_vol y añade 1 a vol_hist\n",
    "price_hist.append(price)\n",
    "exec_vol = 1\n",
    "exec_vol += exec_vol\n",
    "vol_hist.append(exec_vol)\n",
    "\n",
    "# TODO: utiliza la función apropiada para calcula el algo_vwap\n",
    "algo_vwap = _compute_algo_vwap()\n",
    "# guarda el algo_vwap en algo_vwap_hist\n",
    "algo_vwap_hist.append(algo_vwap)\n",
    "# TODO: calcula el reward utilizando la función apropiada\n",
    "reward = _compute_reward(price, exec_vol)\n",
    "print(reward)\n",
    "\n",
    "def _agg_action() -> float:\n",
    "    price = episode[\"ask1\"].values[state_pos]\n",
    "    price_hist.append(price)\n",
    "    exec_vol = 1\n",
    "    exec_vol += exec_vol\n",
    "    vol_hist.append(exec_vol)\n",
    "    algo_vwap = _compute_algo_vwap()\n",
    "    algo_vwap_hist.append(algo_vwap)\n",
    "    reward = _compute_reward(price, exec_vol)\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b178d7-3383-4b66-98f7-9f6086e8c2a8",
   "metadata": {},
   "source": [
    "### 9. _do_nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a012a-97b8-48c8-afff-710c9dcf4df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _do_nothing() -> float:\n",
    "\"\"\"No hacer nada y devolvemos el reward asociado a la acción\n",
    "\"\"\"\n",
    "# TODO: Repite el proceso de _agg_action\n",
    "# Clue: Precio y volumen ejecutado = 0\n",
    "price = 0\n",
    "exec_vol = 0\n",
    "price_hist.append(price)\n",
    "vol_hist.append(exec_vol)\n",
    "algo_vwap = algo_vwap_hist[-1]\n",
    "algo_vwap_hist.append(algo_vwap)\n",
    "reward = _compute_reward(price, exec_vol)\n",
    "\n",
    "print(reward)\n",
    "\n",
    "def _do_nothing() -> float:\n",
    "    price = 0\n",
    "    exec_vol = 0\n",
    "    price_hist.append(price)\n",
    "    vol_hist.append(exec_vol)\n",
    "    algo_vwap = algo_vwap_hist[-1]\n",
    "    algo_vwap_hist.append(algo_vwap)\n",
    "    reward = _compute_reward(price, exec_vol)\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec702ce8-e5e0-4db3-b8d6-0b00e818229d",
   "metadata": {},
   "source": [
    "### 10. _compute_stop_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a11fda-468e-456c-8be0-7ab45104fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _compute_stop_conditions(self) -> Tuple[bool, bool]:\n",
    "\"\"\"Define las condiciones de parada del episodio\n",
    "Return:\n",
    "    Tiempo agotado, orden completada\n",
    "\"\"\"\n",
    "# TODO: Calcula las variables de parada y devuélvelas en el orden apropiado\n",
    "is_bins_complete = state_pos == episode_bins\n",
    "is_ord_complete = exec_vol == vol_care\n",
    "\n",
    "print(is_bins_complete)\n",
    "print(is_ord_complete)\n",
    "\n",
    "def _compute_stop_conditions() -> Tuple[bool, bool]:\n",
    "    is_bins_complete = state_pos == episode_bins\n",
    "    is_ord_complete = exec_vol == vol_care\n",
    "    return is_bins_complete, is_ord_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b525e135-461c-4793-ba17-bce5a9bd1e65",
   "metadata": {},
   "source": [
    "### 11. _compute_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7223a4-fb3b-42fc-846b-202a92a5f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _compute_done(self) -> bool:\n",
    "\"\"\" Reglas de finalización del episodio.\n",
    "\"\"\"\n",
    "# TODO: Calcula las condiciones de parada utilizando la función adecuada\n",
    "conditions = _compute_stop_conditions()\n",
    "is_bins_complete = conditions[0]\n",
    "is_ord_complete = conditions[1]\n",
    "# TODO: Devuelve done == True si se cumplen cualquiera de las condiciones\n",
    "done = is_bins_complete or is_ord_complete\n",
    "\n",
    "print(done)\n",
    "\n",
    "def _compute_done() -> bool:\n",
    "    conditions = _compute_stop_conditions()\n",
    "    is_bins_complete = conditions[0]\n",
    "    is_ord_complete = conditions[1]\n",
    "    done = is_bins_complete or is_ord_complete\n",
    "    return done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c80517a-2459-4b58-b3a3-75fb4c930c1b",
   "metadata": {},
   "source": [
    "### 12. _compute_done_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d477aad-ba07-401c-9fe3-5c3f7fe80f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _compute_done_reward(self) -> float:\n",
    "# TODO: Free style\n",
    "_, is_ord_complete = _compute_stop_conditions()\n",
    "rwd_factor = not is_ord_complete\n",
    "done_reward = -1 * rwd_factor\n",
    "\n",
    "print(done_reward)\n",
    "\n",
    "def _compute_done_reward() -> float:\n",
    "    _, is_ord_complete = _compute_stop_conditions()\n",
    "    rwd_factor = not is_ord_complete\n",
    "    done_reward = -1 * rwd_factor\n",
    "    return done_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1643cd7-55b8-4923-acc5-a2c6c62e8a6b",
   "metadata": {},
   "source": [
    "### 13. action_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc33a11-0313-4011-8635-1123c021dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def action_sample() -> int:\n",
    "\"\"\"\n",
    "Devuelve una acción aleatoria. El valor ha de corresponder \n",
    "con las keys de actions_fn.\n",
    "\"\"\"\n",
    "# TODO: Toma una acción aleatoria\n",
    "# Opcional: ¿Qué distribución de prob es mejor para la exploración?\n",
    "p = vol_care / episode.shape[0]\n",
    "action = np.random.choice([0, 1], p=[1-p, p])\n",
    "\n",
    "print(action)\n",
    "\n",
    "def action_sample() -> int:\n",
    "    p = vol_care / episode.shape[0]\n",
    "    action = np.random.choice([0, 1], p=[1-p, p])\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d5a8f-f2ef-44ba-96c5-121cca049527",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e71837-a1c9-450f-9708-ea0de32fb40f",
   "metadata": {},
   "source": [
    "### step\n",
    "Comprobemos que todo va bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c068aff-cfbb-4aa8-8b1a-654d9229461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = action_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdd73e5-1bc5-4a3f-9042-991887810a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def step(action) -> Tuple[np.array, float, bool, dict]:\n",
    "\"\"\" Evalua la acción, calcula la recompensa, devuelve el \n",
    "nuevo estado y si el episodio ha terminado.\n",
    "\"\"\"\n",
    "market_vwap = _compute_market_vwap()\n",
    "act_fn = actions_fn.get(action)\n",
    "if act_fn is None:\n",
    "    raise ValueError(\n",
    "        f\"Invalid action {action}. Valid actions {actions_fn.keys()}\"\n",
    "    )\n",
    "\n",
    "reward = act_fn()\n",
    "\n",
    "market_vwap_hist.append(market_vwap)\n",
    "reward_hist.append(reward)\n",
    "\n",
    "state_pos += 1\n",
    "\n",
    "done = _compute_done()\n",
    "\n",
    "if done:\n",
    "    reward += _compute_done_reward()\n",
    "    observation = None\n",
    "else:\n",
    "    observation = observation_builder()\n",
    "\n",
    "print(f'observation: {np.array(observation)}')\n",
    "print(f'reward: {reward}')\n",
    "print(f'done: {done}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
